"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
"""
import torch
import numpy as np
import pandas as pd
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import os
from config.paths import PATHS


def load_embeddings(embeddings_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö embeddings"""
    data = np.load(embeddings_path, allow_pickle=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º dataframe –∏–∑ CSV
    train_df = pd.read_csv(os.path.join(PATHS['processed_data'], 'split', 'train.csv'))
    test_df = pd.read_csv(os.path.join(PATHS['processed_data'], 'split', 'test.csv'))
    full_df = pd.concat([train_df, test_df], ignore_index=True)
    
    return {
        'embeddings': data['embeddings'],
        'image_names': list(data['image_names']),
        'dataframe': full_df
    }

def search_products(query, model, processor, image_embeddings, image_names, dataframe, top_k=5, device='cpu'):
    """
    –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
    
    Args:
        query: —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        model: –¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è CLIP –º–æ–¥–µ–ª—å
        processor: CLIP processor
        image_embeddings: numpy array —Å embeddings –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_names: —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∞–π–ª–æ–≤
        dataframe: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    
    Returns:
        list of dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    model.eval()
    
    # –ö–æ–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    with torch.no_grad():
        inputs = processor(text=[query], return_tensors="pt", padding=True, truncation=True)
        text_features = model.get_text_features(input_ids=inputs['input_ids'].to(device))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        text_features = text_features.cpu().numpy()
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
    similarities = np.dot(image_embeddings, text_features.T).squeeze()
    
    # –¢–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = []
    for idx in top_indices:
        img_name = image_names[idx]
        score = similarities[idx]
        row = dataframe[dataframe['image'] == img_name].iloc[0]
        
        results.append({
            'image_name': img_name,
            'score': float(score),
            'display_name': row['display name'],
            'description': row['description'],
            'category': row['category']
        })
    
    return results


def print_results(query, results):
    """–≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∫–æ–Ω—Å–æ–ª—å"""
    print("\n" + "="*80)
    print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê: '{query}'")
    print("="*80 + "\n")
    
    for i, result in enumerate(results, 1):
        print(f"{i}.  {result['display_name']}")
        print(f"    –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result['category']}")
        print(f"    {result['description'][:70]}...")
        print(f"    Score: {result['score']:.4f}")
        print(f"    –§–∞–π–ª: {result['image_name']}")
        print()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model_name = "openai/clip-vit-base-patch32"
    model = CLIPModel.from_pretrained(model_name, use_safetensors=True)
    processor = CLIPProcessor.from_pretrained(model_name)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
    checkpoint_path = os.path.join(PATHS['checkpoints'], 'clip_best.pt')
    
    # –ï—Å–ª–∏ –Ω–µ—Ç best, –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π epoch
    if not os.path.exists(checkpoint_path):
        checkpoint_path = os.path.join(PATHS['checkpoints'], 'clip_epoch_4.pt')
    
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–≤–æ–¥ test_score
        if 'test_score' in checkpoint:
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω checkpoint (Test Score: {checkpoint['test_score']:.2f})")
        elif 'history' in checkpoint and 'test_score' in checkpoint['history']:
            test_score = checkpoint['history']['test_score'][-1]
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω checkpoint (Test Score: {test_score:.2f})")
        else:
            epoch = checkpoint.get('epoch', '?')
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω checkpoint (—ç–ø–æ—Ö–∞ {epoch})")
    else:
        print("‚ö† Checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º embeddings
    print("–ó–∞–≥—Ä—É–∑–∫–∞ embeddings...")
    embeddings_path = os.path.join(PATHS['processed_data'], 'image_embeddings.npz')
    data = load_embeddings(embeddings_path)
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data['image_names'])} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n")
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
    print("="*80)
    print("–°–ò–°–¢–ï–ú–ê –ü–û–ò–°–ö–ê –¢–û–í–ê–†–û–í")
    print("="*80)
    print("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞)\n")
    
    while True:
        query = input("üîç –ó–∞–ø—Ä–æ—Å: ").strip()
        
        if query.lower() in ['exit', 'quit', 'q']:
            print("\n–ü–æ–∏—Å–∫ –æ–∫–æ–Ω—á–µ–Ω üëã")
            break
        
        if not query:
            continue
        
        # –ü–æ–∏—Å–∫
        results = search_products(
            query=query,
            model=model,
            processor=processor,
            image_embeddings=data['embeddings'],
            image_names=data['image_names'],
            dataframe=data['dataframe'],
            top_k=5,
            device=device
        )
        
        # –í—ã–≤–æ–¥
        print_results(query, results)


if __name__ == "__main__":
    main()